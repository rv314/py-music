{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install or import libraries\n",
    "\n",
    "#### tensorflow is not being installed with Python 3.12 on Windows build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmitdeeplearning\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmdl\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Self-Study\\virtualenv\\py-music\\.venv\\Lib\\site-packages\\mitdeeplearning\\__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmitdeeplearning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmitdeeplearning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlab1\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmitdeeplearning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlab2\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmitdeeplearning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlab3\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Self-Study\\virtualenv\\py-music\\.venv\\Lib\\site-packages\\mitdeeplearning\\lab1.py:6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01murllib\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Audio\n\u001b[32m     11\u001b[39m cwd = os.path.dirname(\u001b[34m__file__\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import mitdeeplearning as mdl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0-D tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`integer` is a 0-d Tensor: 10 of type torch.int64\n",
      "`decimal` is a 0-d Tensor: 10.0 of type torch.float32\n"
     ]
    }
   ],
   "source": [
    "integer = torch.tensor(10)\n",
    "decimal = torch.tensor(10.0)\n",
    "\n",
    "print(f\"`integer` is a {integer.ndim}-dimension Tensor: {integer} of type {integer.dtype}\")\n",
    "print(f\"`decimal` is a {decimal.ndim}-dimension Tensor: {decimal} of type {decimal.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-D tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`fibonacci` is a 1-dimension Tensor: tensor([ 0,  1,  1,  2,  3,  5,  8, 13]) of type torch.int64\n",
      "`count_to_100` is a 1-dimension Tensor: tensor([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "         15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
      "         29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "         43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100]) of type torch.int64\n"
     ]
    }
   ],
   "source": [
    "fibonacci = torch.tensor([0, 1, 1, 2, 3, 5, 8, 13])\n",
    "count_to_100 = torch.tensor(range(1, 101))\n",
    "\n",
    "print(f\"`fibonacci` is a {fibonacci.dim()}-dimension Tensor: {fibonacci} of type {fibonacci.dtype}\")\n",
    "print(f\"`count_to_100` is a {count_to_100.dim()}-dimension Tensor: {count_to_100} of type {count_to_100.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-D tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = torch.tensor([[1, 2, 3], [0, 9, 8]])\n",
    "\n",
    "assert isinstance(matrix, torch.Tensor)\n",
    "assert matrix.dim() == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-D tensors (image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images is a 4-dimensional tensor of shape: torch.Size([10, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "images = torch.zeros(10, 3, 256, 256)\n",
    "\n",
    "assert isinstance(images, torch.Tensor)\n",
    "assert images.dim() == 4\n",
    "assert images.shape == (10, 3, 256, 256)\n",
    "\n",
    "print(f\"images is a {images.dim()}-dimensional tensor of shape: {images.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix: tensor([[1, 2, 3],\n",
      "        [0, 9, 8]])\n",
      "Slicing by row and getting second row: tensor([0, 9, 8])\n",
      "Slicing by column and getting second column: tensor([2, 9])\n",
      "Slicing by element and getting an element or scalar value: 2\n"
     ]
    }
   ],
   "source": [
    "row_vector = matrix[1]\n",
    "column_vector = matrix[:, 1]\n",
    "scalar = matrix[0, 1]\n",
    "\n",
    "print(f\"matrix: {matrix}\")\n",
    "print(f\"Slicing by row and getting second row: {row_vector}\")\n",
    "print(f\"Slicing by column and getting second column: {column_vector}\")\n",
    "print(f\"Slicing by element and getting an element or scalar value: {scalar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1: 100\n",
      "c2: 100\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(55)\n",
    "b = torch.tensor(45)\n",
    "\n",
    "c1 = torch.add(a, b)\n",
    "c2 = a + b\n",
    "\n",
    "print(f\"c1: {c1}\")\n",
    "print(f\"c2: {c2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Tensor computation function ###\n",
    "\n",
    "# Constructing a simple computation function\n",
    "\n",
    "def func(a, b):\n",
    "  c = torch.add(a, b)\n",
    "  d = torch.sub(b, 1)\n",
    "  e = torch.mul(c, d)\n",
    "  return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_out: 91\n"
     ]
    }
   ],
   "source": [
    "a, b = 5, 8\n",
    "e_out = func(a, b)\n",
    "print(f\"e_out: {e_out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Neural Networks in Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Neural Networ using Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***torch.nn.Module*** in PyTorch is a base class which acts like a framework used to build and train neural networks. \\\n",
    "Dense Layer in neural network is where each neuron a.k.a perceptron is connected with each perceptron in subsequent layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating a dense layer in PyTorch ###\n",
    "\n",
    "class DenseLayer(nn.Module):\n",
    "  ## We initialize our layer with input features and output features\n",
    "  def __init__(self, num_inputs, num_outputs):\n",
    "    ## super() initializes a parent class that we inherit from\n",
    "    super(DenseLayer, self).__init__()\n",
    "    ## Randomly initialize weights and biases\n",
    "    self.weights = torch.nn.Parameter(torch.randn(num_inputs, num_outputs))\n",
    "    self.bias = torch.nn.Parameter(torch.randn(num_outputs))\n",
    "\n",
    "  ## Implement the forward pass\n",
    "  def forward(self, x):\n",
    "    ## Apply weights and biases on input tensor\n",
    "    z = torch.matmul(x, self.weights) + self.bias\n",
    "    ## Apply the activation function (sigmoid in this case) on z to get output y\n",
    "    y = torch.sigmoid(z)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([1, 2])\n",
      "output shape: torch.Size([1, 3])\n",
      "output results: tensor([[0.1874, 0.9526, 0.6919]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## Testing the dense layer\n",
    "num_inputs = 2\n",
    "num_outputs = 3\n",
    "layer = DenseLayer(num_inputs, num_outputs)\n",
    "\n",
    "x_input = torch.tensor([[1, 2.]])\n",
    "y = layer(x_input)\n",
    "\n",
    "print(f\"input shape: {x_input.shape}\")\n",
    "print(f\"output shape: {y.shape}\")\n",
    "print(f\"output results: {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Neural Network using Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***nn.Module*** allows us to conviniently create a neural network based on the number of input and outputs provided.\\\n",
    "We can also create network using ***Sequential*** and stacking ***Linear*** layer in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define model using nn.Sequential\n",
    "\n",
    "# define number of inputs and outputs\n",
    "n_input_nodes, n_output_nodes = 2, 3\n",
    "\n",
    "# Model using nn.Sequential\n",
    "model = nn.Sequential(nn.Linear(n_input_nodes, n_output_nodes), nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([1, 2])\n",
      "output shape: torch.Size([1, 3])\n",
      "output results: tensor([[0.6092, 0.4315, 0.6462]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Testing sequential model\n",
    "x_input = torch.tensor([[1, 2.]])\n",
    "model_output = model(x_input)\n",
    "\n",
    "print(f\"input shape: {x_input.shape}\")\n",
    "print(f\"output shape: {model_output.shape}\")\n",
    "print(f\"output results: {model_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***nn.Module*** allows us to create custom models by subclassing, we can also group layers together.\\\n",
    "\n",
    "This allows us to customize:\n",
    "1. Layers\n",
    "2. Training loops\n",
    "3. Activation functions\n",
    "4. Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a model with subclassing\n",
    "\n",
    "class LinearWithSigmoid(nn.Module):\n",
    "  def __init__(self, num_inputs, num_outputs):\n",
    "    super(LinearWithSigmoid, self).__init__()\n",
    "    ## Define the linear layer\n",
    "    self.linear = nn.Linear(num_inputs, num_outputs)\n",
    "    self.activation = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, x):\n",
    "    linear_output = self.linear(x)\n",
    "    output = self.activation(linear_output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([1, 2])\n",
      "output shape: torch.Size([1, 3])\n",
      "output: tensor([[0.3803, 0.6546, 0.5285]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## Testing the model\n",
    "input_dim, output_dim = 2, 3\n",
    "model = LinearWithSigmoid(input_dim, output_dim)\n",
    "x = torch.tensor([[1, 2.0]])\n",
    "y = model(x)\n",
    "\n",
    "print(f\"input shape: {x.shape}\")\n",
    "print(f\"output shape: {y.shape}\")\n",
    "print(f\"output: {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with Identify option in Forward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model with identity parameter\n",
    "\n",
    "class LinearWithIdentity(nn.Module):\n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super(LinearWithIdentity, self).__init__()\n",
    "    self.linear = nn.Linear(input_dim, output_dim)\n",
    "    self.activation = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, x, isidentity=False):\n",
    "    x_input = self.linear(x)\n",
    "    if isidentity:\n",
    "      output = x_input\n",
    "      return output\n",
    "    else:\n",
    "      output = self.activation(x_input)\n",
    "      return output\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input : tensor([[1., 2.]])\n",
      "output without identity: tensor([[0.3788, 0.2029, 0.4661]], grad_fn=<SigmoidBackward0>)\n",
      "output with identity: tensor([[-0.4946, -1.3682, -0.1356]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## Testing the identity model\n",
    "input_dim, output_dim = 2, 3\n",
    "model = LinearWithIdentity(input_dim, output_dim)\n",
    "x_input = torch.tensor([[1, 2.0]])\n",
    "output_without_identity = model(x_input)\n",
    "output_with_identity = model(x_input, isidentity=True)\n",
    "\n",
    "print(f\"input : {x_input}\")\n",
    "print(f\"output without identity: {output_without_identity}\")\n",
    "print(f\"output with identity: {output_with_identity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
