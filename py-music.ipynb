{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Generation using RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a RNN for music generation using PyTorch. ABC notations are being used for this training, since they are in text format, they are suitable to use to train a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMET ML to track model experiments\n",
    "import comet_ml\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Remaining imports\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import functools\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 COMET API KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "comet_api_key = os.getenv('COMET_API_KEY')\n",
    "\n",
    "# Validation\n",
    "assert comet_api_key is not None, \"Please set COMET_API_KEY in .env file\"\n",
    "# TODO: Need to setup CUDA\n",
    "assert torch.cuda.is_available(), \"CUDA not available\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "s = load_data()\n",
    "\n",
    "# Print one of the samples\n",
    "example = s[0]\n",
    "print(\"Example of a sample:\")\n",
    "print(example)\n",
    "\n",
    "play_song(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all the lyrics, sort and de-duplicate\n",
    "all_lyrics = \"\\n\\n\".join(s)\n",
    "\n",
    "# Unique characters\n",
    "vocab = sorted(set(all_lyrics))\n",
    "\n",
    "print(f\"Unique characters in the dataset: {len(vocab)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Vectorize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to convert characters to indices\n",
    "char_to_index = {c: i for i, c in enumerate(vocab)}\n",
    "\n",
    "# Simple function to convert indices to characters\n",
    "index_to_char = {i: c for i, c in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "#print(f\"index_to_char: {len(index_to_char)}\")\n",
    "#print(f\"idx2char: {len(idx2char)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{')\n",
    "for char, _ in zip(char_to_index, range(10)):\n",
    "    print(f'  {repr(char)}: {char_to_index[char]}')\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Vectorize the songs string ###\n",
    "\n",
    "'''TODO: Write a function to convert the all songs string to a vectorized\n",
    "    (i.e., numeric) representation. Use the appropriate mapping\n",
    "    above to convert from vocab characters to the corresponding indices.\n",
    "\n",
    "  NOTE: the output of the `vectorize_string` function\n",
    "  should be a np.array with `N` elements, where `N` is\n",
    "  the number of characters in the input string\n",
    "'''\n",
    "def vectorize_string(string):\n",
    "    return np.array([char_to_index[c] for c in string])\n",
    "  \n",
    "\n",
    "vectorized_songs = vectorize_string(all_lyrics)\n",
    "# print(vectorized_songs[:100])\n",
    "assert isinstance(vectorized_songs, np.ndarray), \"returned result should be a np array\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f'{repr(all_lyrics[:10])} ---- characters mapped to int ----> {vectorized_songs[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_songs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 Function to create batches of data based on sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Batch definition to create training examples ###\n",
    "\n",
    "def get_batch(vectorized_songs, seq_length, batch_size):\n",
    "  # the length of the vectorized songs string\n",
    "  n = vectorized_songs.shape[0] - 1\n",
    "  # randomly choose the starting indices for the examples in the training batch\n",
    "  idx = np.random.choice(n-seq_length, batch_size)\n",
    "\n",
    "  # TODO: construct a list of input sequences for the training batch\n",
    "  input_batch = [vectorized_songs[i : i+seq_length] for i in idx]\n",
    "\n",
    "  # TODO: construct a list of output sequences for the training batch\n",
    "  output_batch = [vectorized_songs[i+1 : i+seq_length+1] for i in idx]\n",
    "\n",
    "  # x_batch, y_batch provide the true inputs and targets for network training\n",
    "  # Creating a tensor from a list of numpy.ndarrays is extremely slow. \n",
    "  # Converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor.\n",
    "  #x_batch = np.array(input_batch)\n",
    "  #y_batch = np.array(output_batch)\n",
    "  x_batch = torch.tensor(np.array(input_batch), dtype=torch.long)\n",
    "  y_batch = torch.tensor(np.array(output_batch), dtype=torch.long)\n",
    "\n",
    "  return x_batch, y_batch\n",
    "\n",
    "# Simple tests\n",
    "args = (vectorized_songs, 10, 2)\n",
    "x_batch, y_batch = get_batch(*args)\n",
    "print(\"Input: \", x_batch)\n",
    "print(\"Target: \", y_batch)\n",
    "\n",
    "assert x_batch.shape == (2, 10), \"Incorrect batch shape\"\n",
    "assert y_batch.shape == (2, 10), \"Incorrect batch shape\"\n",
    "print(\"Passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch, y_batch = get_batch(vectorized_songs, seq_length=5, batch_size=1)\n",
    "\n",
    "for i, (input_idx, target_idx) in enumerate(zip(x_batch[0], y_batch[0])):\n",
    "    print(f\"Step {i}\")\n",
    "    print(f\"   input: {input_idx} ({repr(idx2char[input_idx.item()])})\")\n",
    "    print(f\"   expected output: {target_idx} ({repr(idx2char[target_idx.item()])})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 RNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1 Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Defining the RNN ####\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "  def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
    "    super(LSTMModel, self).__init__()\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    # embedding layer\n",
    "    # Layer 1: Embedding layer to transform indices into dense vectors\n",
    "    # of fixed size (embedding_dim)\n",
    "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "    # LSTM layer\n",
    "    # Layer 2: LSTM with `hidden_size` number of hidden units\n",
    "    self.lstm = nn.LSTM(embedding_dim, hidden_size, batch_first=True)\n",
    "\n",
    "    # Layer 3: Linear layer (fully connected layer) that maps the LSTM layer's output\n",
    "    # to the number of characters we have in our vocabulary\n",
    "    self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "  def init_hidden(self, batch_size, device):\n",
    "      # Initialize hidden and cell states\n",
    "      return (torch.zeros(1, batch_size, self.hidden_size).to(device),\n",
    "              torch.zeros(1, batch_size, self.hidden_size).to(device))\n",
    "    \n",
    "  def forward(self, x, state=None, return_state=False):\n",
    "      \n",
    "      x = self.embedding(x)\n",
    "      if state is None:\n",
    "        state = self.init_hidden(x.size(0), x.device)\n",
    "      out, state = self.lstm(x, state)\n",
    "      out = self.linear(out)\n",
    "      return out if not return_state else (out, state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2 Instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate the model with some hyperparameters\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "hidden_size = 1024\n",
    "batch_size = 8\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = LSTMModel(vocab_size, embedding_dim, hidden_size).to(device)\n",
    "\n",
    "# Model summary\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.3 Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test model with sample data\n",
    "\n",
    "x, y = get_batch(vectorized_songs, seq_length=100, batch_size=16)\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "pred = model(x)\n",
    "print(f\"Input shape: {x.shape} # (batch_size, seq_length)\")\n",
    "print(f\"Prediction shape: {pred.shape} # (batch_size, seq_length, vocab_size)\")\n",
    "print(f'Pred data type: {pred.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = torch.multinomial(torch.softmax(pred[0], dim=1), num_samples=1)\n",
    "sampled_indices = sampled_indices.squeeze(-1).cpu().numpy()\n",
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Input \\n {repr(''.join(idx2char[x[0].cpu()]))}\")\n",
    "print()\n",
    "print(f\"Next char predictions \\n {repr(''.join(idx2char[sampled_indices]))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.4 Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss function\n",
    "\n",
    "cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "def compute_loss(label, logits):\n",
    "  \"\"\"\n",
    "  Inputs:\n",
    "    label: target tensor (batch_size, seq_len)\n",
    "    logits: model's prediction (batch_size, seq_len, vocab_size)\n",
    "\n",
    "  Outputs:\n",
    "    loss: scalar value\n",
    "  \"\"\"\n",
    "  \n",
    "  # Batch the labels so that the shape of the labels should be (batch_size * seq_len)\n",
    "  batched_labels = label.view(-1)\n",
    "  #blabel = torch.tensor(batched_labels, dtype=torch.long)\n",
    "\n",
    "  # Batch the logits so that the shape of the logits should be (batch_size * seq_len, vocab_size)\n",
    "  batched_logits = logits.view(-1, logits.size(-1))\n",
    "\n",
    "  # Compute the loss\n",
    "  loss = cross_entropy_loss(batched_logits, batched_labels)\n",
    "\n",
    "  return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute loss on the prediction from the untrained model\n",
    "\n",
    "y.shape\n",
    "pred.shape\n",
    "\n",
    "example_batch_loss = compute_loss(y, pred)\n",
    "\n",
    "print(f'Prediction shape: {pred.shape} # (batch size, seq_len, vocab_size)')\n",
    "print(f'Scalar loss: {example_batch_loss.mean().item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.5 Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameter setting and optimization\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# Model params\n",
    "params = dict(\n",
    "  num_training_iters = 3000,   # Increase to train longer\n",
    "  batch_size = 8,    # Experiment between 1 and 64\n",
    "  seq_length = 100,   # Experiment between 50 and 100\n",
    "  learning_rate = 5e-3,  # Experiment between 1e-5 and 1e-1\n",
    "  embedding_dim = 256,\n",
    "  hidden_size = 1024    # Experiment between 1 and 2048\n",
    ")\n",
    "\n",
    "# Checkpoint location\n",
    "checkpoint_dir = 'training_checkpoint'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "chk_point_prefix = os.path.join(checkpoint_dir, \"chk_point\")\n",
    "final_model = os.path.join(checkpoint_dir, \"final_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Experiment Tracking with Comet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create function to track experiments\n",
    "\n",
    "def create_experiment():\n",
    "  # stop prev experiments\n",
    "  if 'experiment' in locals():\n",
    "    experiment.end()\n",
    "\n",
    "  # Inititate the comet experiment for tracking\n",
    "  experiment = comet_ml.Experiment(\n",
    "    api_key=comet_api_key,\n",
    "    project_name='py-music_'\n",
    "  )\n",
    "  # Log params (defined above) to the experiment\n",
    "  for param, value in params.items():\n",
    "    experiment.log_parameter(param, value)\n",
    "  experiment.flush()\n",
    "\n",
    "  return experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define optimizer and training operation\n",
    "\n",
    "model = LSTMModel(\n",
    "  vocab_size=vocab_size, \n",
    "  embedding_dim=params['embedding_dim'], \n",
    "  hidden_size=params['hidden_size']\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "\n",
    "def train_step(x, y):\n",
    "  # set model to train mode\n",
    "  model.train()\n",
    "\n",
    "  # Zero gradients for every step\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  # Forward pass\n",
    "  y_hat = model(x)\n",
    "\n",
    "  # Compute loss\n",
    "  loss = compute_loss(y, y_hat)\n",
    "\n",
    "  # Backward pass\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "source": [
    "### 2. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "\n",
    "plotter = Plotter(sec=2, xlabel='Iterations', ylabel='Loss')\n",
    "experiment = create_experiment()\n",
    "\n",
    "if hasattr(tqdm, '_instances'): tqdm._instances.clear\n",
    "for iter in tqdm(range(params[\"num_training_iters\"])):\n",
    "\n",
    "  # Grab a batch and propogate through the network\n",
    "  x_batch, y_batch = get_batch(vectorized_songs, params['seq_length'], params['batch_size'])\n",
    "\n",
    "  # Convert numpy arrays in to PyTorch tensors\n",
    "  x_batch = torch.tensor(np.array(x_batch), dtype=torch.long)\n",
    "  y_batch = torch.tensor(np.array(y_batch), dtype=torch.long)\n",
    "\n",
    "  # Take a train step\n",
    "  loss = train_step(x_batch, y_batch)\n",
    "\n",
    "  # Log loss to the Comet interface\n",
    "  experiment.log_metric(\"loss\", loss.item(), step=iter)\n",
    "\n",
    "  # Update the progress bar and visualize in notebook\n",
    "  history.append(loss.item())\n",
    "  plotter.plot(history)\n",
    "\n",
    "  # Save the model\n",
    "  if iter % 100 == 0:\n",
    "    torch.save(model.state_dict(), chk_point_prefix)\n",
    "\n",
    "# Save the final trained model\n",
    "torch.save(model.state_dict(), final_model)\n",
    "experiment.flush()\n",
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
